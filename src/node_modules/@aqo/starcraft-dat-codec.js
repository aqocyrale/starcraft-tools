'use strict';

// import

const FileSystem = require('fs');

// export

module.exports = {
	datBytesToObject,
	objectToDatBytes,
	datFileToJsonFile,
	jsonFileToDatFile,
};

// functions

/**
 * @param {Uint8Array} datBytes
 * @param {Array<[ valueByteSize: Integer, attributeKey: String, isChunked: Boolean ]>} attributeDescriptors
 * @param {Array<String>} entryNames
 * @returns { entryName: { attributeKey: value, ... }, ... }
 */
function datBytesToObject(datBytes, attributeDescriptors, entryNames) {
	const object = {};
	for (const entryName of entryNames) {
		object[entryName] = {};
	}

	let datByteIndex = 0;
	for (const [ valueByteSize, attributeKey, isChunked ] of attributeDescriptors) {
		for (const entryName of entryNames) {
			const valueBytes = datBytes.slice(datByteIndex, datByteIndex + valueByteSize);
			datByteIndex += valueByteSize;
			object[entryName][attributeKey] = isChunked
				? readUint16LEChunks(valueBytes)
				: readUintLE(valueBytes);
		}
	}

	return object;
}

function objectToDatBytes(object) {
	throw Error('TODO: objectToDatBytes');
}

function datFileToJsonFile(inputDatFilePath, inputTxtFilePath, outputJsonFilePath, attributeDescriptors) {
	const datBytes = new Uint8Array(FileSystem.readFileSync(inputDatFilePath));
	const entryNames = FileSystem.readFileSync(inputTxtFilePath, 'utf8').trim().split('\n').map(it => it.trim());
	const object = datBytesToObject(datBytes, attributeDescriptors, entryNames);
	FileSystem.writeFileSync(outputJsonFilePath, JSON.stringify(object, null, '\t'), 'utf8');
}

function jsonFileToDatFile(inputJsonFilePath, outputDatFilePath, outputTxtFilePath) {
	throw Error('TODO: jsonFileToDatFile');
}

function readUint16LEChunks(buffer) {
	const numbers = [];
	for (let i = 0; i < buffer.length; i += 2) {
		numbers.push(readUintLE(buffer.slice(i, i + 2)));
	}
	return numbers;
}

function readUintLE(buffer) {
	let number = 0;
	for (let i = 0; i < buffer.length; ++i) {
		number += buffer[i] << (8 * i);
	}
	return number;
}
